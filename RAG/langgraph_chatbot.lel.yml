# File: RAG/langgraph_chatbot.lel.yml
name: langgraph_chatbot
type: workflow
description: |
  High-level workflow using conditional nodes to decide when to use retrieval,
  when to fallback to a safe reply, and how to orchestrate memory + generation.
inputs:
  - input: string
  - session_id: string
steps:
  - id: intent_classifier
    type: llm
    params:
      model: "tinyllama-1.1b-chat-v1.0"
      prompt: |
        Classify the user's intent for ALS assistant. Output one of: "ask_als",
        "personal", "out_of_scope".
        USER: {input}
  - id: branch
    type: switch
    params:
      condition: "intent_classifier.output"
      cases:
        ask_als:
          - call: chatbot_with_memory
            with:
              input: input
              session_id: session_id
        personal:
          - call: chatbot_with_memory
            with:
              input: input
              session_id: session_id
        out_of_scope:
          - run: default_out_of_scope_reply
  - id: default_out_of_scope_reply
    type: prompt
    params:
      template: |
        I'm sorry â€” I don't have the information to help with that topic. For
        medical or legal advice, please consult a licensed professional.
outputs:
  - answer: string
